{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:35:21.767828Z",
     "end_time": "2023-11-30T14:35:28.015124Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gxb18167\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from config import get_config\n",
    "import generate_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import BertLMHeadModel, BartTokenizer\n",
    "from data import ZuCo_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:35:28.015124Z",
     "end_time": "2023-11-30T14:35:29.808759Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "task_name = \"task1, task2, taskNRv2\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:35:29.815349Z",
     "end_time": "2023-11-30T14:35:29.824716Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "''' set up dataloader '''\n",
    "\n",
    "whole_dataset_dicts = []\n",
    "'''\n",
    "if 'task1' in task_name:\n",
    "    dataset_path_task1 = r'I:\\Science\\CIS-YASHMOSH\\niallmcguire\\ZuCo\\task1-SR\\pickle\\task1-SR-dataset.pickle'\n",
    "    with open(dataset_path_task1, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n",
    "\n",
    "if 'task2' in task_name:\n",
    "    dataset_path_task2 = r'I:\\Science\\CIS-YASHMOSH\\niallmcguire\\ZuCo\\task2-NR\\pickle\\task2-NR-dataset.pickle'\n",
    "    with open(dataset_path_task2, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n",
    "\n",
    "if 'task3' in task_name:\n",
    "    dataset_path_task3 = r'I:\\Science\\CIS-YASHMOSH\\niallmcguire\\ZuCo\\task3-TSR\\pickle\\task3-TSR-dataset.pickle'\n",
    "    with open(dataset_path_task3, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n",
    "'''\n",
    "if 'taskNRv2' in task_name:\n",
    "    dataset_path_taskNRv2 = r'I:\\Science\\CIS-YASHMOSH\\niallmcguire\\ZuCo\\task2-NR-2.0\\pickle\\task2-NR-2.0-dataset.pickle'\n",
    "    with open(dataset_path_taskNRv2, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:35:29.824716Z",
     "end_time": "2023-11-30T14:37:14.442889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 1 task datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded in\", len(whole_dataset_dicts), \"task datasets\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:37:14.446742Z",
     "end_time": "2023-11-30T14:37:14.458027Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "Task_Dataset_List = whole_dataset_dicts\n",
    "if not isinstance(whole_dataset_dicts,list):\n",
    "    Task_Dataset_List = [whole_dataset_dicts]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:37:15.712184Z",
     "end_time": "2023-11-30T14:37:15.736812Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word embeddings: 2397\n",
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['YAC', 'YAG', 'YAK', 'YDG', 'YDR', 'YFR', 'YFS', 'YHS', 'YIS', 'YLS', 'YMD', 'YMS', 'YRH', 'YRK', 'YRP', 'YSD', 'YSL', 'YTL']\n",
      "train divider = 279\n",
      "dev divider = 313\n",
      "[INFO]initializing a train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gxb18167\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:775: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "++ adding task to dataset, now we have: 4490\n",
      "[INFO]input tensor size: torch.Size([56, 840])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "train_set = ZuCo_dataset(whole_dataset_dicts, 'train', tokenizer, subject = 'ALL', eeg_type = 'GD', bands = ['_t1','_t2','_a1','_a2','_b1','_b2','_g1','_g2'], setting = 'unique_sent', is_add_CLS_token = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:37:16.362712Z",
     "end_time": "2023-11-30T14:42:56.936254Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "4490"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:43:20.155521Z",
     "end_time": "2023-11-30T14:43:20.205734Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:11:39.931850Z",
     "end_time": "2023-11-30T14:11:39.968252Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:11:39.962736Z",
     "end_time": "2023-11-30T14:11:39.991300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:11:39.975486Z",
     "end_time": "2023-11-30T14:11:53.139674Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:14:03.664516Z",
     "end_time": "2023-11-30T14:14:03.680807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:11:53.190122Z",
     "end_time": "2023-11-30T14:11:53.208484Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:11:53.211837Z",
     "end_time": "2023-11-30T14:11:53.289045Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:11:53.237065Z",
     "end_time": "2023-11-30T14:11:53.301889Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:11:53.251923Z",
     "end_time": "2023-11-30T14:11:53.302999Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:11:53.264974Z",
     "end_time": "2023-11-30T14:11:53.302999Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_eeg_word_embedding(word, eeg_type = 'GD', bands = ['_t1','_t2','_a1','_a2','_b1','_b2','_g1','_g2']):\n",
    "    EEG_frequency_features = []\n",
    "    EEG_word_level_label = word['content']\n",
    "    for band in bands:\n",
    "        EEG_frequency_features.append(word['word_level_EEG'][eeg_type][eeg_type+band])\n",
    "    word_eeg_embedding = np.concatenate(EEG_frequency_features)\n",
    "    if len(word_eeg_embedding) != 105*len(bands):\n",
    "        print(f'expect word eeg embedding dim to be {105*len(bands)}, but got {len(word_eeg_embedding)}, return None')\n",
    "        word_eeg_embedding = None\n",
    "    else:\n",
    "        word_eeg_embedding = word_eeg_embedding.reshape(105, 8)\n",
    "\n",
    "    return word_eeg_embedding, EEG_word_level_label\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T14:11:53.289546Z",
     "end_time": "2023-11-30T14:11:53.340604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#print number of unique words in each task\n",
    "for Task_Dataset in Task_Dataset_List:\n",
    "    subjects = list(Task_Dataset.keys())\n",
    "    print('[INFO]using subjects: ', subjects)\n",
    "    total_num_sentence = len(Task_Dataset[subjects[0]])\n",
    "    print(f'[INFO]total number of sentences = {total_num_sentence}')\n",
    "    unique_words = set()\n",
    "    for key in subjects:\n",
    "        for i in range(total_num_sentence):\n",
    "            if Task_Dataset[key][i] is not None:\n",
    "                sentence_object = Task_Dataset[key][i]\n",
    "                for word in sentence_object['word']:\n",
    "                    unique_words.add(word['content'])\n",
    "    print(f'[INFO]total number of unique words = {len(unique_words)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T10:13:58.129454Z",
     "end_time": "2023-11-30T10:13:58.226976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Main loop, looping through each task\n",
    "for Task_Dataset in Task_Dataset_List:\n",
    "    subjects = list(Task_Dataset.keys())\n",
    "    print('[INFO]using subjects: ', subjects)\n",
    "\n",
    "    total_num_sentence = len(Task_Dataset[subjects[0]])\n",
    "\n",
    "    train_divider = int(0.8*total_num_sentence)\n",
    "    dev_divider = train_divider + int(0.1*total_num_sentence)\n",
    "\n",
    "    print(f'train size = {train_divider}')\n",
    "    print(f'dev size = {dev_divider}')\n",
    "\n",
    "    EEG_word_level_embeddings = []\n",
    "    EEG_word_level_labels = []\n",
    "    print('[INFO]initializing a train set...')\n",
    "    for key in subjects:\n",
    "        print(f'key = {key}')\n",
    "        for i in range(train_divider):\n",
    "            if Task_Dataset[key][i] is not None:\n",
    "                sentence_object = Task_Dataset[key][i]\n",
    "                for word in sentence_object['word']:\n",
    "                    word_eeg_embedding, EEG_word_level_label = get_eeg_word_embedding(word)\n",
    "                    if word_eeg_embedding is not None and torch.isnan(torch.from_numpy(word_eeg_embedding)).any() == False:\n",
    "                        EEG_word_level_embeddings.append(word_eeg_embedding)\n",
    "                        EEG_word_level_labels.append(EEG_word_level_label)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T10:09:16.013980Z",
     "end_time": "2023-11-30T10:09:34.765819Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(EEG_word_level_labels)\n",
    "#count unique items in list\n",
    "unique, counts = np.unique(EEG_word_level_labels, return_counts=True)\n",
    "print(len(unique))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T10:15:06.779979Z",
     "end_time": "2023-11-30T10:15:06.851774Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "train_data = []\n",
    "for i in range(len(EEG_word_level_embeddings)):\n",
    "   train_data.append([EEG_word_level_embeddings[i], EEG_word_level_labels[i]])\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T13:08:08.563536Z",
     "end_time": "2023-11-20T13:08:08.593593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T10:09:43.649211Z",
     "end_time": "2023-11-30T10:09:43.683293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "# Save the lists to a file using pickle\n",
    "with open('EEG_Text_Pairs.pkl', 'wb') as file:\n",
    "    pickle.dump(EEG_word_level_embeddings, file)\n",
    "    pickle.dump(EEG_word_level_labels, file)\n",
    "\n",
    "# To load the lists from the file:\n",
    "with open('EEG_Text_Pairs.pkl', 'rb') as file:\n",
    "    EEG_word_level_embeddings = pickle.load(file)\n",
    "    EEG_word_level_labels = pickle.load(file)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T13:08:33.702027Z",
     "end_time": "2023-11-20T13:08:33.722919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T13:08:36.452532Z",
     "end_time": "2023-11-20T13:08:38.562553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#sant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:45:16.996483Z",
     "end_time": "2023-11-08T14:45:17.009985Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:45:17.014943Z",
     "end_time": "2023-11-08T14:45:17.024566Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

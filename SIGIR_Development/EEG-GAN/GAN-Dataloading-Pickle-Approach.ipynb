{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:19:19.350939Z",
     "end_time": "2023-11-03T15:19:19.382227Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from config import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from transformers import BertLMHeadModel, BartTokenizer\n",
    "from data import ZuCo_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:19:19.574263Z",
     "end_time": "2023-11-03T15:19:19.629634Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "task_name = \"task1, task2, task3, taskNRv2\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:19:19.774713Z",
     "end_time": "2023-11-03T15:19:19.834859Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "''' set up dataloader '''\n",
    "whole_dataset_dicts = []\n",
    "if 'task1' in task_name:\n",
    "    dataset_path_task1 = r'C:\\Users\\gxb18167\\PycharmProjects\\EEG-To-Text\\dataset\\ZuCo\\task1-SR\\pickle\\task1-SR-dataset.pickle'\n",
    "    with open(dataset_path_task1, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n",
    "if 'task2' in task_name:\n",
    "    dataset_path_task2 = r'C:\\Users\\gxb18167\\PycharmProjects\\EEG-To-Text\\\\dataset\\ZuCo\\task2-NR\\pickle\\task2-NR-dataset.pickle'\n",
    "    with open(dataset_path_task2, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n",
    "if 'task3' in task_name:\n",
    "    dataset_path_task3 = r'C:\\Users\\gxb18167\\PycharmProjects\\EEG-To-Text\\\\dataset\\ZuCo\\task3-TSR\\pickle\\task3-TSR-dataset.pickle'\n",
    "    with open(dataset_path_task3, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n",
    "if 'taskNRv2' in task_name:\n",
    "    dataset_path_taskNRv2 = r'C:\\Users\\gxb18167\\PycharmProjects\\EEG-To-Text\\dataset\\ZuCo\\task2-NR-2.0\\pickle\\task2-NR-2.0-dataset.pickle'\n",
    "    with open(dataset_path_taskNRv2, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:19:19.976519Z",
     "end_time": "2023-11-03T15:20:32.443151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 4 task datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded in\", len(whole_dataset_dicts), \"task datasets\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:20:32.496039Z",
     "end_time": "2023-11-03T15:20:32.522355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "Task_Dataset_List = whole_dataset_dicts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:20:32.539070Z",
     "end_time": "2023-11-03T15:21:52.058948Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n#Main loop, looping through each task\\nfor Task_Dataset in Task_Dataset_List:\\n    subjects = list(Task_Dataset.keys())\\n    print('[INFO]using subjects: ', subjects)\\n\\n    total_num_sentence = len(Task_Dataset[subjects[0]])\\n\\n    train_divider = int(0.8*total_num_sentence)\\n    dev_divider = train_divider + int(0.1*total_num_sentence)\\n\\n    print(f'train size = {train_divider}')\\n    print(f'dev size = {dev_divider}')\\n\\n    print('[INFO]initializing a train set...')\\n    for key in subjects:\\n        print(f'key = {key}')\\n        for i in range(train_divider):\\n\\n            print(len(Task_Dataset[key][i]))\\n\""
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Main loop, looping through each task\n",
    "for Task_Dataset in Task_Dataset_List:\n",
    "    subjects = list(Task_Dataset.keys())\n",
    "    print('[INFO]using subjects: ', subjects)\n",
    "\n",
    "    total_num_sentence = len(Task_Dataset[subjects[0]])\n",
    "\n",
    "    train_divider = int(0.8*total_num_sentence)\n",
    "    dev_divider = train_divider + int(0.1*total_num_sentence)\n",
    "\n",
    "    print(f'train size = {train_divider}')\n",
    "    print(f'dev size = {dev_divider}')\n",
    "\n",
    "    print('[INFO]initializing a train set...')\n",
    "    for key in subjects:\n",
    "        print(f'key = {key}')\n",
    "        for i in range(train_divider):\n",
    "\n",
    "            print(len(Task_Dataset[key][i]))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:21:52.066876Z",
     "end_time": "2023-11-03T15:21:52.085798Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "#Loading in one task, with one subject for example\n",
    "Task_Dataset = Task_Dataset_List[0]\n",
    "\n",
    "subjects = list(Task_Dataset.keys())\n",
    "\n",
    "#total_num_sentence = len(Task_Dataset[subjects[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:24:35.386688Z",
     "end_time": "2023-11-03T15:24:35.408134Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "total_num_sentence = len(Task_Dataset['ZAB'])\n",
    "train_divider = int(0.8*total_num_sentence)\n",
    "dev_divider = train_divider + int(0.1*total_num_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:24:35.605531Z",
     "end_time": "2023-11-03T15:24:35.625231Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['content', 'sentence_level_EEG', 'answer_EEG', 'word', 'word_tokens_has_fixation', 'word_tokens_with_mask', 'word_tokens_all'])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example: Task1 contains x number of subjects, each subject contains a list of dictionaries (sentences)\n",
    "Task_Dataset['ZAB'][0].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:25:53.132267Z",
     "end_time": "2023-11-03T15:25:53.237977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:29:09.732691Z",
     "end_time": "2023-11-03T15:29:09.757031Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "sentence_object = Task_Dataset['ZAB'][0]\n",
    "target_string = sentence_object['content']\n",
    "target_string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:29:17.920536Z",
     "end_time": "2023-11-03T15:29:17.947645Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "'Presents a good case while failing to provide a reason for us to care beyond the very basic dictums of human decency.'"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-03T15:29:21.035278Z",
     "end_time": "2023-11-03T15:29:21.151203Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-30T12:11:58.424830Z",
     "end_time": "2023-11-30T12:12:03.205419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gxb18167\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from config import get_config\n",
    "import generate_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import BertLMHeadModel, BartTokenizer\n",
    "from data import ZuCo_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T12:12:03.194852Z",
     "end_time": "2023-11-30T12:12:04.596273Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "task_name = \"task1, task2, taskNRv2\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T12:12:04.596273Z",
     "end_time": "2023-11-30T12:12:04.612846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "''' set up dataloader '''\n",
    "\n",
    "whole_dataset_dicts = []\n",
    "'''\n",
    "if 'task1' in task_name:\n",
    "    dataset_path_task1 = r'I:\\Science\\CIS-YASHMOSH\\niallmcguire\\ZuCo\\task1-SR\\pickle\\task1-SR-dataset.pickle'\n",
    "    with open(dataset_path_task1, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n",
    "\n",
    "if 'task2' in task_name:\n",
    "    dataset_path_task2 = r'I:\\Science\\CIS-YASHMOSH\\niallmcguire\\ZuCo\\task2-NR\\pickle\\task2-NR-dataset.pickle'\n",
    "    with open(dataset_path_task2, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n",
    "\n",
    "if 'task3' in task_name:\n",
    "    dataset_path_task3 = r'I:\\Science\\CIS-YASHMOSH\\niallmcguire\\ZuCo\\task3-TSR\\pickle\\task3-TSR-dataset.pickle'\n",
    "    with open(dataset_path_task3, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n",
    "'''\n",
    "if 'taskNRv2' in task_name:\n",
    "    dataset_path_taskNRv2 = r'I:\\Science\\CIS-YASHMOSH\\niallmcguire\\ZuCo\\task2-NR-2.0\\pickle\\task2-NR-2.0-dataset.pickle'\n",
    "    with open(dataset_path_taskNRv2, 'rb') as handle:\n",
    "        whole_dataset_dicts.append(pickle.load(handle))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T12:12:04.612846Z",
     "end_time": "2023-11-30T12:13:57.096632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 1 task datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded in\", len(whole_dataset_dicts), \"task datasets\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T12:13:57.102436Z",
     "end_time": "2023-11-30T12:13:57.119590Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "Task_Dataset_List = whole_dataset_dicts\n",
    "if not isinstance(whole_dataset_dicts,list):\n",
    "    Task_Dataset_List = [whole_dataset_dicts]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T12:13:57.119590Z",
     "end_time": "2023-11-30T12:13:57.187546Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]loading 1 task datasets\n",
      "[INFO]using subjects:  ['YAC', 'YAG', 'YAK', 'YDG', 'YDR', 'YFR', 'YFS', 'YHS', 'YIS', 'YLS', 'YMD', 'YMS', 'YRH', 'YRK', 'YRP', 'YSD', 'YSL', 'YTL']\n",
      "train divider = 279\n",
      "dev divider = 313\n",
      "[INFO]initializing a train set...\n",
      "['Henry', 'Ford,', 'with', 'son', 'Edsel,', 'founded', 'Ford', 'Foundation', 'in', '1936', 'local', 'philanthropic', 'organization', 'broad', 'charter', 'promote', 'human', 'welfare.']\n",
      "['this', 'initial', 'success,', 'Ford', 'left', 'Edison', 'Illuminating', 'and,', 'with', 'other', 'investors,', 'formed', 'Detroit', 'Automobile', 'Company.']\n",
      "['With', 'his', 'interest', 'race', 'cars,', 'formed', 'second', 'company,', 'Henry', 'Ford', 'Company.']\n",
      "['During', 'this', 'period,', 'personally', 'drove', 'his', 'Quadricycle', 'victory', 'a', 'race', 'against', 'Alexander', 'Winton,', 'well-known', 'driver', 'heavy', 'favorite', 'on', 'October', '10,', '1901.']\n",
      "['Ford', 'was', 'forced', 'of', 'the', 'company', 'by', 'investors,', 'including', 'Henry', 'M.', 'Leland', 'in', '1902,', 'and', 'company', 'reorganized', 'Cadillac.']\n",
      "['1891,', 'Ford', 'became', 'an', 'engineer', 'with', 'the', 'Edison', 'Illuminating', 'Company,', 'after', 'promotion', 'Chief', 'Engineer', '1893,', 'had', 'enough', 'and', 'money', 'devote', 'attention', 'personal', 'experiments', 'internal', 'combustion', 'engines.']\n",
      "['experiments', 'culminated', '1896', 'the', 'completion', 'his', 'own', 'self-propelled', 'vehicle', 'named', 'the', 'Quadricycle,']\n",
      "['Ford', 'was', 'born', 'on', 'prosperous', 'farm', 'Springwells', 'Township', 'Dearborn,', 'Michigan)', 'parents,', 'William', 'Ford', '(1826-1905)', 'Mary', 'Litogot', '(c1839-1876),', 'County', 'Cork,', 'Ireland.']\n",
      "['the', 'years', 'between', 'wars,', 'Henry', 'Ford', 'supported', 'Adolf', \"Hitler's\", 'Nazi', 'regime.']\n",
      "['is', 'also', 'some', 'evidence', 'Henry', 'gave', 'Adolf', 'Hitler', 'direct', 'financial', 'backing', 'Hitler', 'was', 'first', 'starting', 'out', 'politics.']\n",
      "['can', 'part', 'traced', 'statements', 'from', 'Kurt', 'Ludecke,', \"Germany's\", 'representative', 'the', 'U.S.', 'the', '1920s,', 'Winifred', 'Wagner,', 'daughter-in-law', 'Richard', 'Wagner,', 'said', 'they', 'requested', 'funds', 'Ford', 'aid', 'the', 'National', 'Socialist', 'movement', 'Germany.']\n",
      "['Although', 'Ford', 'often', 'credited', 'the', 'idea,', 'contemporary', 'sources', 'indicate', 'the', 'concept', 'its', 'development', 'came', 'employees', 'Clarence', 'Avery,', 'Peter', 'Martin,', 'Charles', 'Sorensen,', 'C.H.', 'Wills.']\n",
      "['Henry', 'Ford', 'advocated', 'long-time', 'associate', 'Harry', 'Bennett', 'to', 'take', 'spot.']\n",
      "[\"Edsel's\", 'widow', 'Eleanor,', 'had', 'inherited', \"Edsel's\", 'voting', 'stock,', 'wanted', 'son', 'Henry', 'II', 'take', 'over', 'position.']\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "['Alexander', 'Rae', 'Baldwin', 'III', '(born', 'April', '3,', '1958,', 'Massapequa,', 'Long', 'Island,', 'New', 'York,', 'USA)', 'is', 'an', 'American', 'actor', 'who', 'the', 'oldest', 'best', 'known', 'the', '\"Baldwin', 'brothers\",', 'brothers', 'Daniel,', 'Stephen', 'William.']\n",
      "['is', 'of', 'three', 'quarters', 'Irish', 'one', 'quarter', 'French', 'descent.']\n",
      "['Baldwin', 'has', 'appeared', 'movies', 'such', 'The', 'Cooler,', 'The', 'Hunt', 'Red', 'October,', 'Beetlejuice,', 'Ghosts', 'Mississippi,', 'Talk', 'Radio,', 'Final', 'Fantasy:', 'Spirits', 'Within', '(voice),', 'Cat', 'Hat,', 'Pearl', 'Harbor,', 'Thomas', 'the', 'Magic', 'Railroad,', 'Along', 'Came', 'Polly,', 'SpongeBob', 'SquarePants', 'Movie,', 'The', 'Aviator.']\n",
      "['Baldwin', 'young,', 'had', 'job', 'a', 'busboy', 'at', 'famous', 'New', 'York', 'City', 'disco', 'Studio', '54.']\n",
      "['He', 'was', 'married', 'actress', 'Kim', 'Basinger', 'from', '1993', '2002.']\n",
      "['liberal', 'Democrat,', 'always', 'had', 'active', 'interest', 'in', 'politics', 'frequently', 'rumored', 'to', 'be', 'candidate', 'public', 'office.']\n",
      "['particular,', 'Baldwin', 'one', 'of', 'frequent', 'hosts', 'of', 'Saturday', 'Night', 'Live,', 'leading', 'show', 'eleven', 'also', 'making', 'cameo', 'appearances', 'regularly.']\n",
      "['played', 'William', 'Barrett', 'Travis', 'movie', 'about', 'Alamo', 'called', 'Thirteen', 'Days', 'Glory.']\n",
      "['1998,', 'he', 'began', 'narrating', 'American', 'version', \"children's\", 'series', 'Thomas', 'Tank', 'Engine', 'Friends.']\n",
      "['infamous', 'his', '1994', 'on', 'Night', 'Live', 'potrays', 'Armstrong,', 'scoutmaster', 'who', 'pedophile,', 'rips', 'shirt', 'puts', 'mouth', 'around', 'Adam', \"Sandler's\", 'neck.']\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "['1954', 'she,', 'along', 'Bing', 'Crosby,', 'Danny', 'Kaye,', 'and', 'Vera-Ellen,', 'starred', 'movie', 'White', 'Christmas.']\n",
      "[\"Clooney's\", 'first', 'recordings,', 'May', 'of', '1946', 'were', 'Columbia', 'Records', 'as', 'singer', 'the', 'band', 'Tony', 'Pastor.']\n",
      "['Rosemary', 'Clooney', 'married', 'times,', 'twice', 'Jose', 'Ferrer', '(from', '1953', '1961', 'then', 'again', 'from', '1964', '1967)', 'whom', 'had', 'five', 'including', 'actor', 'Miguel', 'Ferrer,', 'born', '1955,', 'Gabriel', 'Ferrer,', 'born', '1956,', 'who', 'married', 'Debby', 'Boone,', 'once', 'Dante', 'DePaolo', '(whom', 'married', '1997).']\n",
      "['Rosemary,', 'Betty,', 'and', 'brother,', 'Nick,', 'well', 'as', 'George', 'Clooney', \"(Nick's\", 'son),', 'became', 'entertainers.']\n",
      "['1945', 'Clooney', 'sisters', 'won', 'a', 'spot', \"Cincinnati's\", 'radio', 'station', 'WLW', 'singers.']\n",
      "['She', 'was', 'Maysville,', 'Kentucky,', 'about', '60', 'Ohio', 'River', 'Cincinnati,', 'Ohio', 'Andrew', 'Joseph', 'Clooney', 'and', 'Frances', 'Marie', 'Guilfoyle,', 'of', 'whom', 'Irish', 'descent', \"(Rosemary's\", 'paternal', 'great-grandparents,', 'Nicholas', 'Clooney', 'Bridget', 'were', 'born', 'Ireland),', 'although', 'paternal', 'grandmother,', 'Crescentia', 'Koch,', 'German.']\n",
      "['Clooney', 'left', 'Columbia,', 'doing', 'number', 'recordings', 'MGM', 'Records', 'then', 'for', 'Coral', 'Records.']\n",
      "['Finally,', 'toward', 'the', 'of', '1958,', 'she', 'with', 'RCA', 'Victor', 'Records,', 'where', 'she', 'stayed', 'until', '1963', 'except', 'doing', 'Reprise', 'Records.']\n",
      "['In', '1964', 'to', 'Reprise', 'shifting', 'the', 'year', 'to', 'Dot', 'Records.']\n",
      "['1966', 'went', 'to', 'United', 'Artists', 'Records.']\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "expect word eeg embedding dim to be 840, but got 0, return None\n",
      "++ adding task to dataset, now we have: 4456\n",
      "[INFO]input tensor size: torch.Size([56, 840])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "train_set = ZuCo_dataset(whole_dataset_dicts, 'train', tokenizer, subject = 'ALL', eeg_type = 'GD', bands = ['_t1','_t2','_a1','_a2','_b1','_b2','_g1','_g2'], setting = 'unique_sent', is_add_CLS_token = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T12:13:57.139179Z",
     "end_time": "2023-11-30T12:14:08.140696Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "set = train_set.__getitem__(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T12:14:08.140696Z",
     "end_time": "2023-11-30T12:14:08.172006Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([840])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T12:14:08.158722Z",
     "end_time": "2023-11-30T12:14:08.190984Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word embeddings: 2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gxb18167\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:775: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_samples\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_synthetic_samples\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mset\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\EEG-To-Text\\SIGIR_Development\\EEG-GAN\\generate_samples.py:167\u001B[0m, in \u001B[0;36mgenerate_synthetic_samples\u001B[1;34m(input_sample)\u001B[0m\n\u001B[0;32m    164\u001B[0m     synthetic_sample \u001B[38;5;241m=\u001B[39m synthetic_sample\u001B[38;5;241m.\u001B[39mresize(\u001B[38;5;241m840\u001B[39m)\n\u001B[0;32m    165\u001B[0m     synthetic_EEG_samples\u001B[38;5;241m.\u001B[39mappend(synthetic_sample)\n\u001B[1;32m--> 167\u001B[0m synthetic_EEG_samples \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43msynthetic_EEG_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moriginal_sample_list\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msynthetic_EEG_samples\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    168\u001B[0m input_sample[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m synthetic_EEG_samples\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m input_sample\n",
      "\u001B[1;31mTypeError\u001B[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "output = generate_samples.generate_synthetic_samples(set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T11:56:48.545882Z",
     "end_time": "2023-11-30T11:56:51.845918Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 1.1309,  1.6070,  1.6184,  2.1316,  2.0072,  0.9559,  0.8318,  0.5798,\n         1.9282,  1.9980,  2.2416,  0.4461,  0.9643,  1.3236,  1.3490,  1.5629,\n         0.8374,  1.2983,  1.8015,  0.7936,  0.5445,  1.6599,  1.0273,  1.1412,\n         0.7551,  0.7453,  1.0093,  1.2919,  0.8880,  1.0048,  0.8213,  0.7432,\n         0.7199,  1.1124,  0.6553,  1.1374,  2.0235,  1.2879,  1.2356,  1.4153,\n         1.5100,  1.5465,  1.1689,  1.4472,  1.8723,  1.3566,  1.4488,  2.1394,\n         2.1715,  2.7332,  2.4510,  3.9470,  2.0833,  2.9682,  3.0889,  3.9591,\n         2.8268,  3.8596,  4.2854,  3.1993,  3.4118,  3.9788,  2.9921,  4.5341,\n         2.8311,  1.8130,  0.6736,  2.7231,  2.8148,  2.9960,  2.6406,  2.6563,\n         2.0183,  2.3531,  2.6251,  2.5584,  2.4389,  2.3401,  1.6259,  1.5897,\n         1.9150,  1.8969,  1.2339,  1.7429,  1.9852,  1.5572,  0.7418,  0.8148,\n         0.9219,  0.9822,  1.1653,  1.3870,  0.7467,  0.5336,  0.6613,  1.3129,\n         0.6483,  0.8139,  1.7328,  0.7149,  1.0943,  0.8470,  0.9822,  1.2890,\n         0.2071,  1.3509,  2.1331,  2.2007,  1.8909,  1.4049,  0.9103,  0.8286,\n         1.5405,  1.7278,  1.3930,  1.4962,  0.6706,  0.8317,  0.9949,  1.2037,\n         1.3458,  0.3776,  1.2171,  1.3023,  0.9316,  0.9665,  1.0201,  1.2427,\n         0.9592,  0.7412,  0.7805,  1.1255,  0.8981,  1.1926,  1.1700,  0.8246,\n         0.9525,  1.0129,  1.0934,  1.2125,  0.7661,  1.3842,  1.4351,  1.1281,\n         1.4875,  2.1867,  2.7873,  2.5841,  2.4716,  2.1764,  1.5369,  2.3955,\n         2.7592,  3.4774,  4.2257,  2.9531,  3.9271,  3.2872,  4.4734,  4.8072,\n         5.2305,  4.6860,  4.8437,  4.9251,  4.7149,  4.6244,  5.1776,  4.3608,\n         4.6187,  3.2779,  2.4558,  0.6366,  3.6475,  4.5351,  3.9298,  3.2407,\n         2.2622,  0.7291,  3.4612,  2.9844,  2.6099,  2.3548,  1.4074,  2.2272,\n         1.9308,  2.2087,  0.9514,  1.3088,  1.7039,  1.2437,  0.9999,  0.9382,\n         0.6820,  0.5661,  1.1593,  1.0112,  0.9157,  0.5754,  1.4722,  0.8477,\n         0.8301,  0.9879,  1.2258,  1.2572,  0.5601,  0.4179,  0.7727,  1.1173,\n         1.7461,  0.1570,  0.5493,  0.9078,  1.2334,  0.9471,  0.7042,  0.3612,\n         0.4754,  0.8485,  1.1507,  0.8296,  0.5903,  0.4259,  0.5252,  0.3674,\n         0.5164,  0.6455,  0.3155,  0.5190,  1.0279,  0.7131,  0.4771,  0.5555,\n         0.3684,  0.4757,  0.1073,  0.1120,  0.6159,  0.1222,  0.6956,  0.3889,\n         0.2401,  0.4927,  0.6316,  0.5026,  0.6920,  0.4649,  0.9002,  1.0333,\n         0.6826,  1.1691,  0.7906,  1.3555,  0.8885,  1.1598,  0.9768,  0.3244,\n         0.9051,  1.3681,  1.5571,  1.9720,  1.5393,  2.2393,  1.8269,  2.3058,\n         2.2393,  2.2388,  1.7986,  2.8206,  2.3101,  2.3738,  2.6086,  2.7730,\n         2.0774,  1.8412,  1.3252,  1.1475,  0.7759,  1.9670,  2.0708,  2.0421,\n         1.3669,  1.4252,  0.6103,  1.4541,  1.4930,  1.5093,  1.4065,  0.8508,\n         1.2597,  0.8931,  1.2421,  0.6074,  1.0056,  0.8612,  0.7729,  0.5962,\n         0.8493,  0.5064,  0.2516,  0.7825,  0.8699,  0.6016,  0.5625,  0.7539,\n         0.5200,  0.6667,  0.4989,  0.7013,  1.0533,  0.5958,  0.4868,  0.7449,\n         0.6929,  1.1506,  0.2342,  0.2746,  0.6442,  0.7737,  1.0974,  0.8152,\n         0.5542,  0.3656,  0.7888,  1.0394,  0.8776,  0.8116,  0.3882,  0.9729,\n         0.6297,  0.6439,  0.5288,  0.1696,  0.7361,  1.1999,  0.5276,  0.9902,\n         0.6528,  0.9271,  0.8166,  0.6473,  0.6108,  0.6754,  1.3431,  1.1932,\n         1.0589,  0.8737,  0.9234,  1.5124,  1.2857,  1.4472,  1.2868,  1.0911,\n         1.1628,  1.6277,  1.5951,  1.5854,  1.4755,  2.0616,  1.6964,  1.2994,\n         0.8394,  2.0764,  2.3063,  1.8839,  2.2922,  1.8675,  2.3134,  2.2620,\n         2.3922,  3.2377,  2.5613,  3.2923,  3.0603,  2.4275,  2.5141,  2.9601,\n         3.0164,  3.5460,  2.6863,  1.7927,  1.5766,  0.4246,  2.8346,  3.4953,\n         2.7197,  2.2920,  2.1866,  1.4040,  2.4564,  2.1517,  2.7867,  2.1824,\n         0.9302,  2.2944,  2.1414,  2.0195,  1.3663,  1.2780,  2.0094,  1.6792,\n         1.2355,  0.8744,  0.4115,  0.2102,  1.3026,  1.0928,  0.7138,  0.6988,\n         0.4316,  0.6112,  0.6205,  0.4790,  0.4996,  0.8666,  0.5947,  0.2828,\n         0.3327,  0.6071,  0.6995, -0.3428,  0.2992,  0.7106,  1.1110,  1.3107,\n         0.6482,  0.4052,  0.9789,  1.3005,  1.4103,  1.6155,  1.0644,  0.5236,\n         1.2158,  1.4260,  1.0296,  1.2866,  0.7928,  1.4059,  1.3067,  0.9328,\n         1.0570,  1.1115,  1.5254,  1.0705,  0.6344,  1.2813,  1.6967,  1.6427,\n         1.0931,  1.8321,  1.7046,  1.9391,  1.9634,  1.5965,  2.1408,  2.0027,\n         1.6462,  2.6285,  1.9422,  1.8905,  2.1952,  2.2656,  2.4657,  2.3096,\n         1.5641,  0.8332,  2.4684,  2.2299,  2.0939,  2.6915,  2.7489,  2.0278,\n         2.4123,  2.7920,  1.9742,  2.5416,  2.7526,  2.2970,  2.0663,  2.0544,\n         2.5153,  2.0217,  2.2158,  2.4814,  1.4494,  1.3066,  0.3831,  1.7209,\n         1.9292,  2.2105,  1.7025,  1.1763,  0.4742,  1.4736,  1.1841,  1.1503,\n         0.8653,  0.7484,  1.0070,  1.7596,  1.1841,  0.7214,  0.9868,  0.7329,\n         0.8486,  0.6492,  0.4329,  0.5892,  0.6375,  1.1207,  0.7553,  0.4573,\n         0.2885,  0.6019,  0.8409,  0.6465,  0.4821,  0.6381,  1.0983,  0.5488,\n         0.2556,  0.7372,  0.7867,  1.2279, -0.1411,  0.6010,  1.1477,  1.2552,\n         1.3145,  1.1112,  0.6383,  1.1352,  1.6741,  2.0040,  1.5520,  1.0953,\n         1.3212,  1.4868,  1.2852,  1.4603,  1.5553,  1.0750,  1.4394,  1.2815,\n         0.9910,  1.3409,  1.1129,  0.8415,  1.2921,  0.6155,  1.3712,  1.5328,\n         1.2663,  1.4434,  1.4496,  0.9266,  1.2549,  1.7548,  1.3967,  1.7817,\n         1.0653,  1.1198,  1.6493,  1.7945,  1.9648,  1.7258,  1.8303,  2.1311,\n         1.4822,  1.2713,  0.9128,  2.0384,  2.6057,  2.1780,  1.9363,  1.9714,\n         1.8289,  2.2826,  3.6752,  3.0758,  1.9964,  3.1524,  2.5527,  2.0480,\n         2.2672,  3.1196,  2.5618,  2.5349,  2.2631,  2.0296,  1.6151,  0.1228,\n         2.1524,  2.1791,  2.5129,  2.2022,  2.1867,  1.0739,  1.6353,  2.2199,\n         2.0053,  1.7980,  1.4083,  2.1633,  2.1023,  1.8470,  1.5994,  1.5355,\n         1.5551,  1.4906,  1.5403,  1.4834,  1.2211,  0.5022,  1.3426,  1.2980,\n         1.1827,  0.7981,  0.8177,  0.9025,  0.8184,  0.8425,  1.3493,  1.2606,\n         0.5201,  0.5715,  1.0059,  0.9246,  1.6353, -0.1206,  0.6025,  1.8939,\n         1.0584,  1.4532,  1.2675,  0.7310,  1.3704,  1.9075,  1.6535,  1.4380,\n         1.3443,  0.9632,  1.4496,  1.6668,  1.7321,  1.2088,  1.2585,  2.2886,\n         2.2434,  1.6181,  1.6691,  1.5166,  1.3521,  1.5431,  0.4404,  1.5834,\n         1.1767,  1.6227,  1.4109,  1.3966,  1.1460,  1.4422,  1.4669,  1.0512,\n         1.2835,  0.7339,  1.3097,  1.3262,  1.4273,  1.2661,  1.7701,  1.6155,\n         1.5524,  1.7281,  1.3530,  0.6324,  2.0459,  2.2631,  2.1594,  1.8203,\n         1.5186,  2.1727,  2.7068,  3.3137,  2.6697,  2.0821,  3.1058,  2.6287,\n         2.5106,  1.9925,  2.9083,  3.3015,  2.9008,  2.1718,  1.6237,  0.9060,\n         0.1792,  3.2364,  2.2396,  2.3591,  2.2935,  1.5503,  0.4196,  1.8287,\n         1.9491,  1.9385,  1.6567,  1.0233,  1.8055,  1.5085,  1.1611,  1.0697,\n         1.2671,  1.5330,  0.9894,  1.1269,  0.8715,  0.7087,  0.5385,  0.9101,\n         1.2292,  1.1038,  0.5400,  0.8576,  0.9084,  1.0105,  0.8375,  0.9023,\n         0.8400,  0.5065,  0.2738,  0.3676,  0.8005,  1.1542, -0.2844,  0.4281,\n         1.5037,  1.7961,  2.4342,  1.8122,  1.5855,  1.6244,  2.0411,  2.5405,\n         3.8729,  3.3609,  1.2860,  2.4724,  1.6014,  1.8352,  3.3431,  1.7278,\n         2.5818,  3.2187,  0.6153,  2.9023,  2.7884,  2.2219,  2.1132,  0.5078,\n         1.8023,  2.0190,  2.4942,  1.5004,  1.3901,  2.5341,  1.9376,  2.0571,\n         1.8005,  1.5164,  1.6688,  1.6429,  1.3444,  1.4919,  1.7104,  1.2987,\n         1.1474,  1.4309,  1.0179,  1.6566,  1.7590,  1.3830,  2.4934,  2.2869,\n         1.6395,  1.2961,  2.1362,  2.7368,  3.9573,  2.9321,  1.7089,  3.6922,\n         3.0049,  2.5613,  1.8499,  3.4823,  3.1421,  3.2654,  2.3784,  2.5089,\n         1.2331,  1.0058,  3.8381,  3.1043,  2.4431,  1.5630,  1.6789,  0.3325,\n         1.9647,  2.7655,  2.1285,  1.7197,  1.4545,  2.2092,  2.1135,  1.6668,\n         1.4296,  1.6823,  1.1810,  1.8020,  1.3594,  1.7398,  1.0995,  2.4888,\n         1.2990,  1.5687,  1.3254,  0.9313,  1.9485,  1.0067,  0.7795,  1.5260,\n         1.6995,  2.1484,  0.4662,  0.4076,  0.8167,  1.4098,  1.7459, -0.3196])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T11:56:54.996605Z",
     "end_time": "2023-11-30T11:56:55.061953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_eeg_word_embedding(word, eeg_type = 'GD', bands = ['_t1','_t2','_a1','_a2','_b1','_b2','_g1','_g2']):\n",
    "    EEG_frequency_features = []\n",
    "    EEG_word_level_label = word['content']\n",
    "    for band in bands:\n",
    "        EEG_frequency_features.append(word['word_level_EEG'][eeg_type][eeg_type+band])\n",
    "    word_eeg_embedding = np.concatenate(EEG_frequency_features)\n",
    "    if len(word_eeg_embedding) != 105*len(bands):\n",
    "        print(f'expect word eeg embedding dim to be {105*len(bands)}, but got {len(word_eeg_embedding)}, return None')\n",
    "        word_eeg_embedding = None\n",
    "    else:\n",
    "        word_eeg_embedding = word_eeg_embedding.reshape(105, 8)\n",
    "\n",
    "    return word_eeg_embedding, EEG_word_level_label\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T11:12:30.450103Z",
     "end_time": "2023-11-30T11:12:30.499899Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#print number of unique words in each task\n",
    "for Task_Dataset in Task_Dataset_List:\n",
    "    subjects = list(Task_Dataset.keys())\n",
    "    print('[INFO]using subjects: ', subjects)\n",
    "    total_num_sentence = len(Task_Dataset[subjects[0]])\n",
    "    print(f'[INFO]total number of sentences = {total_num_sentence}')\n",
    "    unique_words = set()\n",
    "    for key in subjects:\n",
    "        for i in range(total_num_sentence):\n",
    "            if Task_Dataset[key][i] is not None:\n",
    "                sentence_object = Task_Dataset[key][i]\n",
    "                for word in sentence_object['word']:\n",
    "                    unique_words.add(word['content'])\n",
    "    print(f'[INFO]total number of unique words = {len(unique_words)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T10:13:58.129454Z",
     "end_time": "2023-11-30T10:13:58.226976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "#Main loop, looping through each task\n",
    "for Task_Dataset in Task_Dataset_List:\n",
    "    subjects = list(Task_Dataset.keys())\n",
    "    print('[INFO]using subjects: ', subjects)\n",
    "\n",
    "    total_num_sentence = len(Task_Dataset[subjects[0]])\n",
    "\n",
    "    train_divider = int(0.8*total_num_sentence)\n",
    "    dev_divider = train_divider + int(0.1*total_num_sentence)\n",
    "\n",
    "    print(f'train size = {train_divider}')\n",
    "    print(f'dev size = {dev_divider}')\n",
    "\n",
    "    EEG_word_level_embeddings = []\n",
    "    EEG_word_level_labels = []\n",
    "    print('[INFO]initializing a train set...')\n",
    "    for key in subjects:\n",
    "        print(f'key = {key}')\n",
    "        for i in range(train_divider):\n",
    "            if Task_Dataset[key][i] is not None:\n",
    "                sentence_object = Task_Dataset[key][i]\n",
    "                for word in sentence_object['word']:\n",
    "                    word_eeg_embedding, EEG_word_level_label = get_eeg_word_embedding(word)\n",
    "                    if word_eeg_embedding is not None and torch.isnan(torch.from_numpy(word_eeg_embedding)).any() == False:\n",
    "                        EEG_word_level_embeddings.append(word_eeg_embedding)\n",
    "                        EEG_word_level_labels.append(EEG_word_level_label)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T10:09:16.013980Z",
     "end_time": "2023-11-30T10:09:34.765819Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(EEG_word_level_labels)\n",
    "#count unique items in list\n",
    "unique, counts = np.unique(EEG_word_level_labels, return_counts=True)\n",
    "print(len(unique))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T10:15:06.779979Z",
     "end_time": "2023-11-30T10:15:06.851774Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "train_data = []\n",
    "for i in range(len(EEG_word_level_embeddings)):\n",
    "   train_data.append([EEG_word_level_embeddings[i], EEG_word_level_labels[i]])\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T13:08:08.563536Z",
     "end_time": "2023-11-20T13:08:08.593593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T10:09:43.649211Z",
     "end_time": "2023-11-30T10:09:43.683293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "# Save the lists to a file using pickle\n",
    "with open('EEG_Text_Pairs.pkl', 'wb') as file:\n",
    "    pickle.dump(EEG_word_level_embeddings, file)\n",
    "    pickle.dump(EEG_word_level_labels, file)\n",
    "\n",
    "# To load the lists from the file:\n",
    "with open('EEG_Text_Pairs.pkl', 'rb') as file:\n",
    "    EEG_word_level_embeddings = pickle.load(file)\n",
    "    EEG_word_level_labels = pickle.load(file)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T13:08:33.702027Z",
     "end_time": "2023-11-20T13:08:33.722919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-20T13:08:36.452532Z",
     "end_time": "2023-11-20T13:08:38.562553Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#sant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:45:16.996483Z",
     "end_time": "2023-11-08T14:45:17.009985Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-08T14:45:17.014943Z",
     "end_time": "2023-11-08T14:45:17.024566Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
